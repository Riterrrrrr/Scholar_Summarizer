# backend/server.py

# å¤´éƒ¨å¼•ç”¨éœ€è¦ç¡®ä¿åŒ…å«è¿™äº›
import os
import uvicorn
import trafilatura
from fastapi import FastAPI, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel
from google import genai # Google å®˜æ–¹æœ€æ–° SDK
from google.genai import types
import time

# ================= é…ç½®åŒºåŸŸ =================

# 1. API é…ç½®
# è¯·å» https://aistudio.google.com/ è·å– API Key
GOOGLE_API_KEY = "AIzaSyCLNsWRfOjc2cZnjTSi5tv3fbRKHjB6TsU"  # ä»˜è´¹ Keyï¼Œè¯·è‡ªè¡Œæ›´æ¢
# GOOGLE_API_KEY = "AIzaSyDFiq3gsNqG_8QK8NqALsKrsYRs8woCUq0"  # å…è´¹ Keyï¼Œè¯·è‡ªè¡Œæ›´æ¢

# 2. æ¨¡å‹é€‰æ‹©
# 2025å¹´æ­¤æ—¶ï¼Œå»ºè®®æŸ¥çœ‹ Google AI Studio æ¨¡å‹åˆ—è¡¨ã€‚
# å¯èƒ½æ˜¯ "gemini-3.0-pro", "gemini-2.0-flash", æˆ– "gemini-1.5-pro"
MODEL_NAME = "gemini-2.5-flash" 

# ================= åˆå§‹åŒ– =================

app = FastAPI(title="Scholar Summarizer Backend")

# é…ç½® CORS (è·¨åŸŸèµ„æºå…±äº«)
# å…è®¸æ¥è‡ªæµè§ˆå™¨æ’ä»¶çš„è¯·æ±‚è®¿é—®æ­¤æœåŠ¡å™¨
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  # åœ¨ç”Ÿäº§ç¯å¢ƒä¸­å»ºè®®é™åˆ¶ä¸ºæ’ä»¶çš„ IDï¼Œä½†åœ¨æœ¬åœ°å¼€å‘ "*" æ²¡é—®é¢˜
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# åˆå§‹åŒ– Gemini å®¢æˆ·ç«¯
client = genai.Client(api_key=GOOGLE_API_KEY)

# å®šä¹‰å‰ç«¯ä¼ æ¥çš„æ•°æ®æ ¼å¼
class URLRequest(BaseModel):
    url: str

# ================= æ ¸å¿ƒå·¥å…·å‡½æ•° =================

def fetch_clean_content(url: str):
    """
    æŠ“å–å¹¶æ¸…æ´—ç½‘é¡µå†…å®¹
    """
    print(f"[*] æ”¶åˆ°æŠ“å–è¯·æ±‚: {url}")
    try:
        # trafilatura è‡ªåŠ¨å¤„ç† User-Agent å’Œ Cookie ç©¿é€
        downloaded = trafilatura.fetch_url(url)
        if downloaded is None:
            return None, "æ— æ³•è¿æ¥åˆ°è¯¥ç½‘é¡µ (Network Error)"
        
        # æå–æ­£æ–‡ï¼Œå»é™¤å¯¼èˆªæ ã€è¡¨æ ¼å’Œè¯„è®º
        text = trafilatura.extract(downloaded, include_comments=False, include_tables=False)
        
        if not text:
            return None, "ç½‘é¡µå†…å®¹æå–ä¸ºç©º (å¯èƒ½æ˜¯çº¯å›¾ç‰‡æˆ– SPA åŠ¨æ€åŠ è½½)"
            
        # æˆªå–å‰ 4000 å­—ç¬¦ (è¶³å¤Ÿè¦†ç›–ç®€ä»‹ï¼Œä¸”èŠ‚çœ Token)
        return text[:4000], None
        
    except Exception as e:
        return None, f"æŠ“å–å¼‚å¸¸: {str(e)}"

def generate_summary_gemini(text_content: str):
    """
    V5.0: é€šç”¨å­¦æœ¯æ€»ç»“æ¡†æ¶ (The Universal Academic Profiler)
    æ—¨åœ¨å…¼å®¹å„ç§å†™ä½œé£æ ¼ï¼ˆæ˜¾æ€§å£°æ˜ã€éšæ€§æè¿°ã€æ„¿æ™¯é©±åŠ¨å‹ï¼‰
    """
    
    # System Instruction: å®šä¹‰ä»»åŠ¡çš„æœ¬è´¨æ˜¯â€œä¿¡æ¯è’¸é¦â€è€Œéç®€å•çš„â€œæ€»ç»“â€
    system_instruction = """
    You are an expert Academic Research Analyst.
    Your objective is to distill a scholar's profile into a precise statement of their *active* research contribution.
    You must distinguish between "what they research" (High Value) and "who they are/what they teach" (Low Value).
    """

    # User Prompt: é€šç”¨å¤„ç†åè®®
    prompt_content = f"""
    Please analyze the text using the following **Universal Research Extraction Protocol**:

    ### Phase 1: Signal Detection (The Funnel)
    Scan the text and extract research topics based on the following hierarchy. **Prioritize the highest level found.**

    * **Level 1: Explicit Temporality (The "Now" Signal)**
        * Look for: "Current research", "Recent projects", "Working on", "In progress", "Latest work".
        * *Action:* If found, this is the primary source.
    
    * **Level 2: Active Investigation (The "Doing" Signal)**
        * Look for strong verbs indicating active inquiry: "Investigates", "Examines", "Conducts research on", "Explores", "Analyzes".
        * *Action:* Use this if Level 1 is missing. This captures the scholar's ongoing work.
    
    * **Level 3: Intent & Impact (The "Goal" Signal)**
        * Look for teleological markers: "Aiming to", "Seeks to", "Goal is to", "Dedicated to improving", "Address the problem of".
        * *Action:* Use this to identify the *purpose* or *application* of their work (often the most descriptive part).

    ### Phase 2: Noise Cancellation (Universal Filters)
    Strictly IGNORE the following categories unless they are the *object* of research:
    * **Pedagogy:** "Taught courses in...", "Engages students...", "Teaching interests".
    * **Biography:** "Earned PhD from...", "Joined faculty in...", "Director of...".
    * **General Affiliation:** Do not assume research topics based solely on the Department name (e.g., "Social Work", "Computer Science") or broad disciplinary labels (e.g., "Law", "Sociology") without specific context.

    ### Phase 3: Synthesis & Compression
    * **Format:** Create a single, high-density English phrase.
    * **Structure:** Start with a dynamic component (Verb/Noun) + Specific Topic + Context/Population.
    * **Faithfulness:** Retain specific terminology (e.g., "incarcerated women", "machine learning fairness") rather than generalizing (e.g., "vulnerable groups", "AI ethics").
    
    ### Constraints
    * **Language:** English ONLY.
    * **Length:** Strictly **10 to 15 words**.

    ### Input Text:
    {text_content}

    ### Output:
    Provide ONLY the final English summary from Phase 3.
    """

    # === æ ¸å¿ƒä¿®æ”¹ï¼šé‡è¯•å¾ªç¯é…ç½® ===
    current_max_tokens = 2048  # åˆå§‹ Token é¢åº¦
    max_retries = 3            # æœ€å¤šå°è¯• 3 æ¬¡
    
    # å®‰å…¨è®¾ç½® (ä¿æŒå…¨å¼€)
    safety_settings = [
        types.SafetySetting(category="HARM_CATEGORY_HARASSMENT", threshold="BLOCK_NONE"),
        types.SafetySetting(category="HARM_CATEGORY_HATE_SPEECH", threshold="BLOCK_NONE"),
        types.SafetySetting(category="HARM_CATEGORY_SEXUALLY_EXPLICIT", threshold="BLOCK_NONE"),
        types.SafetySetting(category="HARM_CATEGORY_DANGEROUS_CONTENT", threshold="BLOCK_NONE"),
    ]

    for attempt in range(max_retries):
        try:
            print(f"[*] ç¬¬ {attempt + 1} æ¬¡å°è¯•ï¼ŒMax Tokens: {current_max_tokens}")

            response = client.models.generate_content(
                model=MODEL_NAME,
                config=types.GenerateContentConfig(
                    system_instruction=system_instruction,
                    temperature=0.2,
                    max_output_tokens=current_max_tokens, # <--- åŠ¨æ€å˜é‡
                    safety_settings=safety_settings,
                ),
                contents=[prompt_content]
            )

            # 1. æ£€æŸ¥æ˜¯å¦å› ä¸º Token ä¸å¤Ÿè€Œæˆªæ–­
            # æ³¨æ„ï¼šä¸åŒç‰ˆæœ¬çš„ SDK å¯¹ finish_reason çš„è®¿é—®æ–¹å¼å¯èƒ½ä¸åŒï¼Œè¿™é‡Œåšä¸ªé€šç”¨åˆ¤æ–­
            finish_reason = str(response.candidates[0].finish_reason)
            
            if "MAX_TOKENS" in finish_reason:
                print(f"[!] Token ä¸è¶³ (MAX_TOKENS)ï¼Œæ­£åœ¨æ‰©å®¹é‡è¯•...")
                current_max_tokens *= 2  # ç¿»å€ï¼š1024 -> 2048 -> 4096
                time.sleep(1) # ç¨å¾®æ­‡ä¸€ç§’ï¼Œé˜²æ­¢æ¥å£é¢‘ç¹
                continue # è¿›å…¥ä¸‹ä¸€æ¬¡å¾ªç¯
            
            # 2. æ£€æŸ¥æ˜¯å¦æœ‰æœ‰æ•ˆæ–‡æœ¬
            if response.text:
                return response.text.strip()
            
            # 3. å¦‚æœæ²¡æ–‡æœ¬ä¹Ÿæ²¡æŠ¥é”™ MAX_TOKENS (å¯èƒ½æ˜¯å®‰å…¨è¿‡æ»¤ç­‰å…¶ä»–åŸå› )
            print(f"[!] å“åº”ä¸ºç©ºï¼ŒæœªçŸ¥åŸå› : {finish_reason}")
            return "Error: No text generated."

        except Exception as e:
            print(f"[!] è°ƒç”¨å¼‚å¸¸: {e}")
            # å¦‚æœæ˜¯ API ç½‘ç»œé”™è¯¯ï¼Œä¹Ÿå¯ä»¥åœ¨è¿™é‡Œé€‰æ‹© continue é‡è¯•
            return f"API Error: {str(e)}"

    return "Error: Exceeded max retries (Model is too chatty!)"

# ================= API æ¥å£ =================

@app.post("/summarize")
async def api_summarize(request: URLRequest):
    """
    ä¾›æµè§ˆå™¨æ’ä»¶è°ƒç”¨çš„æ¥å£
    """
    # 1. æŠ“å–
    text, error = fetch_clean_content(request.url)
    
    if error:
        # è¿”å› 400 é”™è¯¯ç»™å‰ç«¯
        raise HTTPException(status_code=400, detail=error)
    
    # 2. æ€»ç»“
    summary = generate_summary_gemini(text)
    
    # 3. è¿”å› JSON
    return {"summary": summary}

if __name__ == "__main__":
    # å¯åŠ¨æœåŠ¡å™¨ï¼Œç›‘å¬ 8000 ç«¯å£
    print("ğŸš€ åç«¯æœåŠ¡å¯åŠ¨ä¸­... è¯·ä¿æŒæ­¤çª—å£æ‰“å¼€")
    uvicorn.run(app, host="127.0.0.1", port=8000)